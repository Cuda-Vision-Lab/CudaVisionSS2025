{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CCVAE(nn.Module):\n",
    "    def __init__(self, in_channels=3, latent_dim=64, num_classes=3):\n",
    "        super(CCVAE, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = self.make_encoder()\n",
    "        \n",
    "        # Adding num_classes to account for class conditioning\n",
    "        self.fc_mu = nn.Linear(2048 + num_classes, latent_dim)\n",
    "        self.fc_sigma = nn.Linear(2048 + num_classes, latent_dim)\n",
    "        \n",
    "        # Takes latent vector and class embedding\n",
    "        self.decoder_input = nn.Sequential(\n",
    "            nn.Linear(latent_dim + num_classes, 2048),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = self.make_decoder()\n",
    "\n",
    "    def make_encoder(self):\n",
    "        return nn.Sequential(\n",
    "            # Input: (3, 64, 64)\n",
    "            nn.Conv2d(self.in_channels, 16, kernel_size=4, stride=2, padding=1),  # (16, 32, 32)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1),  # (32, 16, 16)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),  # (64, 8, 8)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # (128, 4, 4)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.Flatten()  # 128 * 4 * 4 = 2048\n",
    "        )\n",
    "        \n",
    "    def make_decoder(self):\n",
    "        return nn.Sequential(\n",
    "            # Input: (128, 4, 4)\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # (64, 8, 8)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),  # (32, 16, 16)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=4, stride=2, padding=1),  # (16, 32, 32)\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            \n",
    "            nn.ConvTranspose2d(16, self.in_channels, kernel_size=4, stride=2, padding=1),  # (3, 64, 64)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        \"\"\"Reparameterization trick\"\"\"\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def encode(self, x, c):\n",
    "        \"\"\"\n",
    "        Encode the input image x conditioned on class label c\n",
    "        Args:\n",
    "            x: input image [batch_size, channels, height, width]\n",
    "            c: class labels [batch_size]\n",
    "        \"\"\"\n",
    "        # Convert class labels to one-hot encoding\n",
    "        c_onehot = F.one_hot(c, num_classes=self.num_classes).float()\n",
    "        \n",
    "        # Encode image\n",
    "        x_encoded = self.encoder(x)\n",
    "        \n",
    "        # Concatenate encoded image with class embedding\n",
    "        x_c = torch.cat([x_encoded, c_onehot], dim=1)\n",
    "        \n",
    "        mu = self.fc_mu(x_c)\n",
    "        log_var = self.fc_sigma(x_c)\n",
    "        \n",
    "        return mu, log_var\n",
    "\n",
    "    def decode(self, z, c):\n",
    "        \"\"\"\n",
    "        Decode the latent vector z conditioned on class label c\n",
    "        Args:\n",
    "            z: latent vector [batch_size, latent_dim]\n",
    "            c: class labels [batch_size]\n",
    "        \"\"\"\n",
    "        # Convert class labels to one-hot encoding\n",
    "        c_onehot = F.one_hot(c, num_classes=self.num_classes).float()\n",
    "        \n",
    "        # Concatenate latent vector with class embedding\n",
    "        z_c = torch.cat([z, c_onehot], dim=1)\n",
    "        \n",
    "        # Project and reshape\n",
    "        z_c = self.decoder_input(z_c)\n",
    "        z_c = z_c.view(-1, 128, 4, 4)\n",
    "        \n",
    "        # Decode\n",
    "        x_hat = self.decoder(z_c)\n",
    "        return x_hat\n",
    "        \n",
    "    def forward(self, x, c):\n",
    "        \"\"\"\n",
    "        Forward pass of the conditional VAE\n",
    "        Args:\n",
    "            x: input image [batch_size, channels, height, width]\n",
    "            c: class labels [batch_size]\n",
    "        \"\"\"\n",
    "        # Encode\n",
    "        mu, log_var = self.encode(x, c)\n",
    "        \n",
    "        # Reparameterization trick\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        \n",
    "        # Decode\n",
    "        x_hat = self.decode(z, c)\n",
    "        \n",
    "        return x_hat, (z, mu, log_var)\n",
    "\n",
    "    def sample(self, num_samples, c):\n",
    "        \"\"\"\n",
    "        Generate samples for given class labels\n",
    "        Args:\n",
    "            num_samples: number of samples to generate\n",
    "            c: class labels [num_samples]\n",
    "        \"\"\"\n",
    "        # Sample from standard normal distribution\n",
    "        z = torch.randn(num_samples, self.latent_dim).to(next(self.parameters()).device)\n",
    "        \n",
    "        # Generate samples\n",
    "        samples = self.decode(z, c)\n",
    "        return samples\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
